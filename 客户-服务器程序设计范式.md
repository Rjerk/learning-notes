# 客户/服务器程序设计范式

## TCP 客户程序设计范式

### 停-等

[停-等示例代码](https://github.com/Rjerk/snippets/blob/master/unp/str_cli.cpp)

有两个问题：
1. 进程在被阻塞以等待用户输入期间，看不到注入对端关闭等网络事件。
2. 以停-等模式运作，批处理效率极低。

### select + 阻塞式 I/O

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/iomultiplexing/str_cli_select01.cpp)

调用 select 使得进程能在等待用户输入期间得到网络事件的通知。然而该进程存在不能正确批处理输入的问题，可以使用 shutdown 解决。[解决示例](https://github.com/Rjerk/snippets/blob/master/unp/iomultiplexing/str_cli_select02.cpp)

### 非阻塞式 I/O 

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/nonblock/str_cli_nonblock.cpp)

非阻塞式版本可以防止进程在可做任何有效工作期间发生阻塞，但是让代码变得更加复杂。

### fork 版本

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/nonblock/str_cli_fork.cpp)

使用 fork 派生一个子进程，由父进程（或子进程）处理从客户到服务器的数据，由子进程（或父进程）处理从服务器到客户的程序。

### 线程取代进程

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/thread/strcli_thread.cpp)

线程有时称为轻权进程，因为线程的创建可能比进程的创建快 10~100 倍。

## TCP 服务器程序设计范式

9 种不同的服务器程序设计范式。

### TCP 迭代式服务器程序

迭代服务器总是在完全处理某个客户的请求后才转向下一个客户。

从进程控制角度来看，迭代服务器是最快的，因为不进行任何进程控制。可以让我们测量出服务器处理一定数目客户所需 CPU 时间的一个基准值。

### TCP 并发服务器程序，每个客户一个子进程

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/cs/one_client_one_process/)

用 fork 派生一个子进程来处理每个客户，这样能同时为多个客户服务。客户数目的唯一限制是操作系统对以其名义运行服务器的用户 ID 能够同时拥有多少个子进程的限制。

并发服务器的问题在于为每个客户现场 fork 一个子进程比较耗费 CPU 时间。

### TCP 预先派生子进程服务器程序，accpet 无上锁保护

[示例代码](https://github.com/Rjerk/snippets/tree/master/unp/cs/prefork_unlock_accept)

在服务器启动阶段预先派生一定数量的子进程，当各个客户连接到达时，这些子进程立即就能为它们服务。

这种技术的优点是，无须引入父进程执行 fork 的开销就能处理到新的客户；缺点是，父进程必须预先猜测需要派生多少个子进程。

通过增加一些代码，服务器能应对客户负载的变动。父进程必须做的就是持续监测可用的子进程数，一旦该值降低到某个阈值就派生额外的子进程，一旦超过另一个阈值就终止一些过剩的子进程。

**惊群问题**：服务器进程在程序启动阶段派生 N 个子进程，各自调用 accept 而被内核投入睡眠。当第一个客户端连接到达时，所有 N 个子进程都被唤醒，这是因为所有 N 个子进程所用的监听描述符都指向同一个 socket 结构，致使它们在同一个等待通道上进入睡眠。尽管所有 N 个子进程都被唤醒，但只有最先运行的子进程获得客户端的连接，其余 N-1 个子进程继续回复睡眠。

惊群问题会导致性能受损，如果子进程太多，惊群问题会更严重。

### TCP 预先派生子进程服务器程序，accept 使用文件上锁保护

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/cs/prefork_filelock_accept/)

有些内核不允许多个进程在引用同一个监听描述符上调用 accept。客户端开始连接到服务器后不久，某个子进程的 accept 会返回 `EPROTO` 错误。

解决办法是，预先派生子进程后，accept 使用文件上锁保护（比如用 fcntl 的 POSIX 文件上锁功能），保证每次只有一个子进程阻塞在 accept 调用中，其他子进程则阻塞在试图获取用于保护 accept 的锁上。这种围绕 accpet 上锁增加了服务器的进程控制 CPU 时间。

当多个进程在引用同一个套接字的描述符上调用 `select` 时就会发生冲突，因为在 socket 结构中为存放本套接字就绪之时应该唤醒哪些进程而分配的仅仅是一个进程 ID 的空间。如果有多个进程在等待同一套接字，那么内核必须唤醒的是阻塞在 select 调用中的所有进程，因为它不知道哪些进程受刚变得就绪的这个套接字的影响。如果有多个进程阻塞引用在同一个实体的描述符上，那么最好直接阻塞在诸如 `accept` 函数而不是 `select` 之中。

### TCP 预先派生子进程服务器程序，accept 使用线程上锁保护

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/cs/prefork_threadlock_accept/)

有多种方法可用于实现进程之间的上锁。用 POSIX 文件上锁的方式可移植到所有 POSIX 兼容系统，但是涉及到文件系统操作，可能会比较耗时。

可以改用线程上锁保护 accept，因为它不仅适用于同一进程内各个线程之间的上锁，而且适用于不同进程之间的上锁。

在不同进程之间使用线程上锁要求：
- 互斥锁变量必须存放在所有进程共享的内存区中。
- 必须告知线程函数库这是在不同进程之间共享的互斥锁。

### TCP 预先派生子进程服务器程序，传递描述符

[示例代码](https://github.com/Rjerk/snippets/tree/master/unp/cs/prefork_transferfd_accept)

只让父进程调用 accept，然后把所接受的已连接套接字“传递”给某个子进程。这样做绕过了为所有子进程的 accept 调用提供上锁保护的可能需求，但是需要从父进程到子进程的某种形式的描述符传递，父进程必须跟踪子进程的忙闲状态，以便给空闲子进程传递新的套接字。

### TCP 并发服务器程序，每个客户端一个线程

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/cs/one_client_one_thread/)

如果服务器主机支持线程，就可以改用线程取代子进程，获得性能的提升。

### TCP 预先创建线程服务器程序，每个线程各自 accept

[示例代码](https://github.com/Rjerk/snippets/tree/master/unp/cs/threadpool_main_thread_accept)

在服务器启动阶段预先创建一个线程池以取代为每个客户现场创建一个线程有利于性能加速。

预先创建一个线程池，并让每个线程各自调用 accept，并取代每个线程都阻塞在 accept 调用的做法，改用互斥锁保证任何时刻只有一个线程在调用 accept。

### TCP 预先创建线程服务器程序，主线程统一 accept

[示例代码](https://github.com/Rjerk/snippets/blob/master/unp/cs/threadpool_one_thread_one_accept/)

在程序启动阶段创建一个线程池后只让主线程调用 accept 并把每个客户连接传递给池中某个可用线程。

该范式的设计问题在于，主线程如何把一个已连接套接字传递给线程池中某个可用线程。既然所有线程和所有描述符都在同一个进程之内，就没有必要把一个描述符从一个线程传递到另一个线程。接受线程只需知道这个已连接套接字描述符的值，而描述符传递的并非这个值，而是对这个套接字的引用，因此将返回一个不同于原值的描述符（该套接字的引用计数也被递增）。

